### **üõ°Ô∏è Cyberbullying Detection System**
---

### üìñ Project Description

Cyberbullying is the use of digital platforms to harass, intimidate, or harm others. It can occur anonymously, spread rapidly, and have serious emotional and psychological effects.

This project is an AI-powered system designed to detect online harassment and cyberbullying in text, providing tools to analyze, predict, and prevent harmful content.

---

### üöÄ Key Features

- Detects offensive or harmful content in messages and social media posts  
- Uses **Natural Language Processing (NLP)** and **Machine Learning** algorithms  
- Provides real-time alerts and analysis for potential cyberbullying  
- Supports text classification, sentiment analysis, and context-aware detection  

---

### üõ†Ô∏è Tech Stack

![Python](https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white) 
![TensorFlow](https://img.shields.io/badge/TensorFlow-FF6F00?style=for-the-badge&logo=tensorflow&logoColor=white) 
![PyTorch](https://img.shields.io/badge/PyTorch-EE4C2C?style=for-the-badge&logo=pytorch&logoColor=white) 
![NLTK](https://img.shields.io/badge/NLTK-FF6F00?style=for-the-badge&logo=nltk&logoColor=white) 
![Scikit-Learn](https://img.shields.io/badge/scikit--learn-F7931E?style=for-the-badge&logo=scikit-learn&logoColor=white) 
![Flask](https://img.shields.io/badge/Flask-000000?style=for-the-badge&logo=flask&logoColor=white) 

---

### ‚ö° How It Works

1. Users input text from messages or social media.  
2. Text is preprocessed and analyzed for harmful content.  
3. AI model classifies the text as safe or cyberbullying.  
4. Results are displayed with alerts and severity scores.  

---
